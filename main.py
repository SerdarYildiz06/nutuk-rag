# Gerekli KÃ¼tÃ¼phaneleri Kurulum
# Bu kÃ¼tÃ¼phaneler bilgisayarÄ±nÄ±zda yÃ¼klÃ¼ deÄŸilse, terminalinizde ÅŸu komutlarÄ± Ã§alÄ±ÅŸtÄ±rÄ±n:
# pip install pypdf
# pip install langchain
# pip install sentence-transformers # GÃ¶mme modeli iÃ§in gerekli
# pip install chromadb # ChromaDB iÃ§in gerekli

import os
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_community.embeddings import HuggingFaceEmbeddings # GÃ¶mme modeli iÃ§in eklendi
from langchain_community.vectorstores import Chroma # ChromaDB iÃ§in eklendi

def process_pdf_for_rag(file_path: str):
    """
    Belirtilen PDF dosyasÄ±nÄ± yÃ¼kler, metin temizleme uygular ve RAG iÃ§in parÃ§alara ayÄ±rÄ±r (chunking).

    Args:
        file_path (str): Ä°ÅŸlenecek PDF dosyasÄ±nÄ±n yolu.

    Returns:
        list: TemizlenmiÅŸ ve parÃ§alara ayrÄ±lmÄ±ÅŸ Document nesnelerinin listesi.
              Bir hata oluÅŸursa None dÃ¶ner.
    """
    if not os.path.exists(file_path):
        print(f"Hata: '{file_path}' yolu bulunamadÄ±. LÃ¼tfen dosya yolunu kontrol edin.")
        return None

    print(f"'{file_path}' PDF dosyasÄ± yÃ¼kleniyor ve temizleniyor...")
    try:
        loader = PyPDFLoader(file_path)
        documents = loader.load() # Her sayfa ayrÄ± bir 'Document' objesi olarak gelir
    except Exception as e:
        print(f"PDF yÃ¼kleme sÄ±rasÄ±nda bir hata oluÅŸtu: {e}")
        return None

    cleaned_documents = []
    for doc in documents:
        text_content = doc.page_content

        # --- Temel Temizleme AdÄ±mlarÄ± ---
        # 1. Birden fazla boÅŸluÄŸu tek boÅŸluÄŸa indirgeme
        text_content = ' '.join(text_content.split())
        # 2. Yeni satÄ±r ve satÄ±r baÅŸÄ± karakterlerini boÅŸluÄŸa Ã§evirme
        text_content = text_content.replace('\n', ' ').replace('\r', ' ')
        # 3. BaÅŸtaki ve sondaki boÅŸluklarÄ± kaldÄ±rma
        text_content = text_content.strip()

        # TemizlenmiÅŸ metinle yeni bir Document objesi oluÅŸtur ve metadata'yÄ± kopyala
        cleaned_doc = Document(page_content=text_content, metadata=doc.metadata)
        cleaned_documents.append(cleaned_doc)

    print(f"PDF'den {len(cleaned_documents)} sayfa yÃ¼klendi ve temel temizleme yapÄ±ldÄ±.")

    if not cleaned_documents:
        print("UyarÄ±: PDF'den hiÃ§ metin Ã§Ä±karÄ±lamadÄ± veya tÃ¼m sayfalar boÅŸ Ã§Ä±ktÄ±.")
        return []

    print("Belgeler parÃ§alara (chunk) ayrÄ±lÄ±yor...")
    # --- Chunking (ParÃ§alama) Ä°ÅŸlemi ---
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,       # Her parÃ§anÄ±n maksimum karakter sayÄ±sÄ±
        chunk_overlap=100,     # ParÃ§alar arasÄ±ndaki Ã§akÄ±ÅŸan karakter sayÄ±sÄ±
        length_function=len,   # UzunluÄŸu karakter sayÄ±sÄ±yla Ã¶lÃ§ (varsayÄ±lan)
        is_separator_regex=False # AyÄ±rÄ±cÄ±lar regex mi deÄŸil mi? (VarsayÄ±lan olarak false bÄ±rakÄ±n)
    )

    chunks = text_splitter.split_documents(cleaned_documents)
    print(f"Toplam {len(chunks)} parÃ§a (chunk) oluÅŸturuldu.")

    return chunks

def create_embeddings_from_chunks(chunks: list[Document]):
    """
    OluÅŸturulan parÃ§alardan gÃ¶mme (embedding) vektÃ¶rleri oluÅŸturur.

    Args:
        chunks (list[Document]): ParÃ§alara ayrÄ±lmÄ±ÅŸ Document nesnelerinin listesi.

    Returns:
        HuggingFaceEmbeddings: YÃ¼klenmiÅŸ gÃ¶mme modeli.
        list: Her parÃ§a iÃ§in oluÅŸturulan gÃ¶mme vektÃ¶rlerinin listesi.
    """
    print("GÃ¶mme modeli yÃ¼kleniyor ve parÃ§alar vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
    # TÃ¼rkÃ§e iÃ§in veya genel amaÃ§lÄ± bir model seÃ§in
    embedding_model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    
    try:
        embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)
        print(f"GÃ¶mme modeli yÃ¼klendi: {embedding_model_name}")

        # Her bir parÃ§anÄ±n iÃ§eriÄŸinden gÃ¶mme vektÃ¶rlerini oluÅŸturma
        # Not: LangChain'in vektÃ¶r veritabanlarÄ± genellikle bu adÄ±mÄ± otomatik yapar,
        # ancak burada manuel olarak da gÃ¶sterebiliriz.
        # embedded_chunks = embeddings.embed_documents([chunk.page_content for chunk in chunks])
        # print(f"{len(embedded_chunks)} adet gÃ¶mme vektÃ¶rÃ¼ oluÅŸturuldu.")
        
        # Bu fonksiyon, doÄŸrudan `embeddings` objesini dÃ¶ndÃ¼rÃ¼yor.
        # VektÃ¶r veritabanÄ±na kaydederken parÃ§alar bu modelle embed edilecek.
        return embeddings
    except Exception as e:
        print(f"GÃ¶mme modeli yÃ¼klenirken veya gÃ¶mme oluÅŸturulurken bir hata oluÅŸtu: {e}")
        print("LÃ¼tfen 'sentence-transformers' kÃ¼tÃ¼phanesinin yÃ¼klÃ¼ olduÄŸundan ve internet baÄŸlantÄ±nÄ±zÄ±n olduÄŸundan emin olun.")
        return None

def save_to_chromadb(chunks: list[Document], embeddings_model, persist_directory: str = "rag_chroma_db"):
    """
    ParÃ§alarÄ± ChromaDB vektÃ¶r veritabanÄ±na kaydeder.

    Args:
        chunks (list[Document]): ParÃ§alara ayrÄ±lmÄ±ÅŸ Document nesnelerinin listesi.
        embeddings_model: GÃ¶mme modeli (HuggingFaceEmbeddings).
        persist_directory (str): ChromaDB'nin kaydedileceÄŸi dizin yolu.

    Returns:
        Chroma: ChromaDB vektÃ¶r maÄŸazasÄ± objesi. Hata durumunda None dÃ¶ner.
    """
    if not chunks or not embeddings_model:
        print("Hata: ParÃ§alar veya gÃ¶mme modeli bulunamadÄ±.")
        return None

    print(f"ChromaDB'ye kaydetme iÅŸlemi baÅŸlatÄ±lÄ±yor...")
    print(f"KayÄ±t dizini: {persist_directory}")
    print(f"Kaydedilecek parÃ§a sayÄ±sÄ±: {len(chunks)}")

    try:
        # ChromaDB vektÃ¶r maÄŸazasÄ± oluÅŸturma ve parÃ§alarÄ± kaydetme
        vectorstore = Chroma.from_documents(
            documents=chunks,
            embedding=embeddings_model,
            persist_directory=persist_directory
        )
        
        print(f"âœ… {len(chunks)} parÃ§a baÅŸarÄ±yla ChromaDB'ye kaydedildi.")
        print(f"ğŸ“ VektÃ¶r veritabanÄ± ÅŸu konumda saklanÄ±yor: {persist_directory}")
        
        # VektÃ¶r maÄŸazasÄ±ndaki toplam dokÃ¼man sayÄ±sÄ±nÄ± kontrol etme
        collection = vectorstore._collection
        total_docs = collection.count()
        print(f"ğŸ“Š VektÃ¶r veritabanÄ±ndaki toplam dokÃ¼man sayÄ±sÄ±: {total_docs}")
        
        return vectorstore
        
    except Exception as e:
        print(f"âŒ ChromaDB'ye kaydetme sÄ±rasÄ±nda bir hata oluÅŸtu: {e}")
        print("LÃ¼tfen 'chromadb' kÃ¼tÃ¼phanesinin yÃ¼klÃ¼ olduÄŸundan emin olun.")
        return None

def search_in_vectorstore(vectorstore, query: str, k: int = 5):
    """
    ChromaDB vektÃ¶r maÄŸazasÄ±nda arama yapar.

    Args:
        vectorstore: ChromaDB vektÃ¶r maÄŸazasÄ± objesi.
        query (str): Aranacak sorgu metni.
        k (int): DÃ¶ndÃ¼rÃ¼lecek en benzer dokÃ¼man sayÄ±sÄ±.

    Returns:
        list: En benzer dokÃ¼manlarÄ±n listesi.
    """
    if not vectorstore:
        print("Hata: VektÃ¶r maÄŸazasÄ± bulunamadÄ±.")
        return []

    try:
        print(f"ğŸ” Sorgu: '{query}'")
        print(f"ğŸ“ {k} adet en benzer dokÃ¼man aranÄ±yor...")
        
        # Benzerlik aramasÄ± yapma
        similar_docs = vectorstore.similarity_search(query, k=k)
        
        print(f"âœ… {len(similar_docs)} adet benzer dokÃ¼man bulundu.")
        
        for i, doc in enumerate(similar_docs):
            print(f"\n--- SonuÃ§ {i+1} ---")
            print(f"Kaynak: {doc.metadata.get('source', 'Bilinmiyor')}")
            print(f"Sayfa: {doc.metadata.get('page', 'Bilinmiyor')}")
            print(f"Ä°Ã§erik: {doc.page_content[:200]}...")
            
        return similar_docs
        
    except Exception as e:
        print(f"âŒ Arama sÄ±rasÄ±nda bir hata oluÅŸtu: {e}")
        return []

if __name__ == "__main__":
    # --- KullanÄ±cÄ±dan PDF Dosya Yolu Alma ---
    print("PDF dosya yolunu girin (Ã–rn: C:/Users/KullaniciAdi/Belgelerim/rapor.pdf)")
    pdf_file_path = input("PDF Dosya Yolu: ")

    # PDF'i iÅŸleme ve parÃ§alarÄ± alma
    processed_chunks = process_pdf_for_rag(pdf_file_path)

    if processed_chunks:
        print("\n--- Ä°ÅŸlem SonuÃ§larÄ± ---")
        print(f"Ä°ÅŸlenen toplam parÃ§a sayÄ±sÄ±: {len(processed_chunks)}")

        # Ä°lk birkaÃ§ parÃ§anÄ±n iÃ§eriÄŸini kontrol edelim
        print("\n--- OluÅŸturulan Ä°lk 3 ParÃ§anÄ±n Ä°Ã§eriÄŸi ---")
        for i, chunk in enumerate(processed_chunks[:3]):
            print(f"\n--- ParÃ§a {i+1} ---")
            print(f"Karakter SayÄ±sÄ±: {len(chunk.page_content)}")
            print(f"Metada (Kaynak Dosya, Sayfa NumarasÄ± vb.): {chunk.metadata}")
            print("Ä°Ã§erik BaÅŸlangÄ±cÄ±:")
            print(chunk.page_content[:400]) # Ä°lk 400 karakterini gÃ¶ster
            print("...")
        
        # ParÃ§alardan gÃ¶mme vektÃ¶rleri oluÅŸturma (GÃ¶mme modeli dÃ¶ndÃ¼rÃ¼lÃ¼yor)
        # Bu fonksiyon aslÄ±nda embedding modelini dÃ¶ndÃ¼rÃ¼r, vektÃ¶r veritabanÄ± adÄ±mÄ±nda kullanÄ±lÄ±r
        embeddings_model = create_embeddings_from_chunks(processed_chunks)

        if embeddings_model:
            print("\nParÃ§alardan gÃ¶mme vektÃ¶rleri oluÅŸturma aÅŸamasÄ±na geÃ§ildi.")
            
            # ChromaDB'ye kaydetme iÅŸlemi
            print("\n=== ChromaDB'ye Kaydetme Ä°ÅŸlemi ===")
            vectorstore = save_to_chromadb(processed_chunks, embeddings_model)
            
            if vectorstore:
                print("\nâœ… ChromaDB'ye kaydetme iÅŸlemi tamamlandÄ±!")
                
                # KullanÄ±cÄ±dan arama sorgusu alma
                print("\n=== Arama Testi ===")
                print("ChromaDB'de arama yapmak ister misiniz? (e/h)")
                search_choice = input("SeÃ§iminiz: ").lower()
                
                if search_choice == 'e':
                    while True:
                        query = input("\nArama sorgusu girin (Ã§Ä±kmak iÃ§in 'quit'): ")
                        if query.lower() == 'quit':
                            break
                        
                        search_results = search_in_vectorstore(vectorstore, query)
                        
                        if not search_results:
                            print("HiÃ§ sonuÃ§ bulunamadÄ±.")
                else:
                    print("Arama iÅŸlemi atlandÄ±.")
                    
                print("\nğŸ“‹ VektÃ¶r veritabanÄ± kullanÄ±mÄ±:")
                print("Daha sonra arama yapmak iÃ§in:")
                print("vectorstore = Chroma(persist_directory='rag_chroma_db', embedding_function=embeddings_model)")
                print("results = vectorstore.similarity_search('sorgunuz')")
            else:
                print("\nâŒ ChromaDB'ye kaydetme iÅŸlemi baÅŸarÄ±sÄ±z oldu.")
        else:
            print("\nGÃ¶mme modeli oluÅŸturulamadÄ±. LÃ¼tfen hatalarÄ± kontrol edin.")

    else:
        print("\nPDF iÅŸleme sÄ±rasÄ±nda bir sorun oluÅŸtu, parÃ§alar oluÅŸturulamadÄ±.")
